{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TweetAnalysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEuTp0aWsPIVjaNAk+24ao",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohelbaba/Data-Science/blob/master/Copy_of_TweetAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR22J4drfVUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy as tw\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znVGNNwlfjA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Authentication keys\n",
        "consumer_key= '0q42FevFlZHyuxHyewTT3jEgf'\n",
        "consumer_secret= 'kzq6n4xQKv3a0tNRNhSAN7cm6nwUyjqpiEobkyF39hMcT3VhCj'\n",
        "access_token= '1268944578129932288-yQdmxWVcMcz4jUFQCpKAIeuOFef6Vh'\n",
        "access_token_secret= 'hOf3k9T83BN5PRnLRPIajYHW4uVZHXhu7bHmkgF8HwZre'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwZx3uqwfmxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#API authhandler for tweepy\n",
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmdLB9WqfqXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#search term and fetching tweets \n",
        "search_term =  \"#covid19  -filter:retweets\"\n",
        "tweets = tw.Cursor(api.search,q=search_term,lang=\"en\",since=\"2020-3-20\",until='2020-6-08').items(100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu5pa9xkfqkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove url from tweets preprocessing of tweets\n",
        "def remove_url(txt):\n",
        "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE2bovFzfqxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tweets ready after preprocess..\n",
        "all_tweets = [[remove_url(tweet.text),tweet._json['user']['location'].split(','),[re.findall(r\"#(\\w+)\",tweet.text)]] for tweet in tweets]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rFSQh9k7StK",
        "colab_type": "code",
        "outputId": "e1b2873f-b4e7-44a3-f9d0-ec900c8c2b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "all_tweets[5396]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interestingly Made 6 MONTHS AGOWhy 2020 Will Be A Horrible Year 2020Protests',\n",
              " ['United States'],\n",
              " [['2020Protests']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldSIIE-6iQXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clean the tweets remove punchuation mark\n",
        "def clean_text_round1(text):\n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyoXak2TiQVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clean and store another list called clean_tweets\n",
        "clean_tweets = []\n",
        "for tweet in all_tweets:\n",
        "    clean_tweets.append(clean_text_round1(tweet[0]))\n",
        "    \n",
        "#tokenize each string so we analysis the text\n",
        "token_tweets = [] \n",
        "for i in clean_tweets:\n",
        "    token_tweets.append(i.split())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px41k_pWiQO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data frame with tokenized word\n",
        "df = pd.DataFrame(clean_tweets)\n",
        "df.columns = ['tweets']\n",
        "tokenized_tweet = df['tweets'].apply(lambda x: x.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuP4GDwniQMB",
        "colab_type": "code",
        "outputId": "668d5ec3-164b-4fc4-8d97-00a663d6235d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#importing nltk lib for analysis removing stopword like a,the...\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akvlh4EAiQJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "for i in tokenized_tweet:\n",
        "    for j in list(i):\n",
        "        if j in stop_words:\n",
        "            i.remove(j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Co7z16yiP1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#after removig the stop word and cleaning process again join the word for sentiment analysis\n",
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "\n",
        "df['tweets'] = tokenized_tweet\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQuL6bw9iZ01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create sentimet object usinf textblob and store polarity and subjectivity\n",
        "sentiment_objects = [TextBlob(tweet) for tweet in df['tweets']]\n",
        "sentiment_values = [[tweet.sentiment.polarity, tweet.sentiment.subjectivity,str(tweet)] for tweet in sentiment_objects]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl9a6rXCN56J",
        "colab_type": "code",
        "outputId": "1030b36d-e4de-421a-adef-cc53492f622f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentiment_values[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.4, 0.4, 'heartbreaking yet another example system broken ltc cdnpoli']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N7O7TZdiZnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#adding hashtag into the data with respective tweets\n",
        "for hashtag,sentiment in zip(all_tweets,sentiment_values):\n",
        "    #print(hashtag[2],sentiment)\n",
        "    sentiment.append(hashtag[2][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5ST-cHCO18U",
        "colab_type": "code",
        "outputId": "39f1b840-a30b-49c5-9577-c0a8ef61df78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sentiment_values[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.4,\n",
              " 0.4,\n",
              " 'heartbreaking yet another example system broken ltc cdnpoli',\n",
              " ['COVID19', 'LTC', 'cdnpoli']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5PrIUYNOL4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#adding hashtag into the data with respective tweets\n",
        "for hashtag,sentiment in zip(all_tweets,sentiment_values):\n",
        "    #print(hashtag[2],sentiment)\n",
        "    sentiment.append(hashtag[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBvQK26wnnrv",
        "colab_type": "code",
        "outputId": "fec3c04c-cfaf-4f1e-cea3-91249cac0a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "sentiment_values[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.4,\n",
              " 0.4,\n",
              " 'heartbreaking yet another example system broken ltc cdnpoli',\n",
              " ['COVID19', 'LTC', 'cdnpoli'],\n",
              " ['West Vancouver']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqm_MPlfqkzE",
        "colab_type": "code",
        "outputId": "1a11e44e-7fe8-42b5-8fc5-e399f11050cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip install cloudant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cloudant\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/46/e0935c7be2452fd923606c97122fedf8793731cd306f79e185082a641adb/cloudant-2.13.0-py3-none-any.whl (79kB)\n",
            "\r\u001b[K     |████▏                           | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from cloudant) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.7.0->cloudant) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.7.0->cloudant) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.7.0->cloudant) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.7.0->cloudant) (3.0.4)\n",
            "Installing collected packages: cloudant\n",
            "Successfully installed cloudant-2.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppBheWK0iZg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import clodant package for storing info to cloud for further use\n",
        "from cloudant import cloudant\n",
        "from cloudant.client import Cloudant"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--l7tiPEijr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create cloudant object \n",
        "client = Cloudant('47400d77-738e-4f53-af75-2724098f1441-bluemix', '566317acc09448f54f953a4d7cf344940b44447b297081d1a5d885bfd1e4479b', url='https://47400d77-738e-4f53-af75-2724098f1441-bluemix:566317acc09448f54f953a4d7cf344940b44447b297081d1a5d885bfd1e4479b@47400d77-738e-4f53-af75-2724098f1441-bluemix.cloudantnosqldb.appdomain.cloud', connect=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTQW5Dx0iniT",
        "colab_type": "code",
        "outputId": "be66af79-52c0-46df-b673-8333d9b6c84f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#create database\n",
        "my_database = client.create_database('test_data_tweets1')\n",
        "#printing all databases\n",
        "print('Databases: {0}'.format(client.all_dbs()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Databases: ['myappwithibm', 'student_mangement', 'test_data_tweets', 'test_data_tweets1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eDX6kKgrrer",
        "colab_type": "code",
        "outputId": "39cdb3f5-a1ee-4692-a7c5-28f717b72b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import time\n",
        "sentiment_values[13][4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['London', ' ON/Port Huron', ' MI']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTCAfh6giqUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#document store on cloud with clean tweets\n",
        "dict_tweets = {}\n",
        "for data in sentiment_values:\n",
        "    dict_tweets['polarity'] = data[0]\n",
        "    dict_tweets['subjectivy'] = data[1]\n",
        "    dict_tweets['text'] = data[2]\n",
        "    dict_tweets['Location'] = data[4]\n",
        "    dict_tweets['hashtag'] = data[3]\n",
        "    my_document = my_database.create_document(dict_tweets)\n",
        "    time.sleep(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHwlX4LmirvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}